import re
from nltk.tokenize import TweetTokenizer
import nltk

def preProcessing(twitterText):

	#Remover \n
	twitterText = re.sub("\n+"," ",twitterText)

	#Remover multiplos espaÃ§os
	twitterText = re.sub(" +"," ",twitterText)

	#Remove links
	twitterText = re.sub(r"http\S+", "",twitterText)

	#Remover caracteres especiais
	twitterText = re.sub("[@|#|â€œ|â€|â€™|â€˜|Â®|,|!|?||\[|\]|\.|\"|%|:|\-|_|/|Âª|\(|\)|Â°|\*|ğŸ‡§|ğŸ‡·|\'|ï¸|=]",'',twitterText)

	#Remover nÃºmeros
	twitterText = re.sub("[0-9]+",'',twitterText)

	#Lower case
	twitterText = twitterText.lower()

	#Tokenize
	twitterTokens = TweetTokenizer().tokenize(twitterText)

	#remove stopwords
	stopwords = nltk.corpus.stopwords.words('portuguese')
	stopwords.remove("nÃ£o")
	stopwords.remove("num")
	twitterTokens = [token for token in twitterTokens if (token not in stopwords) ]

	return ' '.joint(twitterTokens)