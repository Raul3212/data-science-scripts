{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romulo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/dataset2018.tsv', header=0, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['classe'] != 'N√£o sei']\n",
    "data['classe'][data['classe'] == 'Rejei√ß√£o'] = 2\n",
    "data['classe'][data['classe'] == 'Neutro'] = 1\n",
    "data['classe'][data['classe'] == 'Aprova√ß√£o'] = 0\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>candidato</th>\n",
       "      <th>marcador</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twe984802485360582656</td>\n",
       "      <td>Ao inv√©s dos petistas estarem buscando livrar ...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twe977572021361168389</td>\n",
       "      <td>@CshmKnCaioHen @Peaotrabalhador @MiguelAMSA61 ...</td>\n",
       "      <td>manuela</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twe977558211447443457</td>\n",
       "      <td>A pergunta √© s√©ria, @manudeputada: quer me pag...</td>\n",
       "      <td>manuela</td>\n",
       "      <td>alysson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>twe977347407011897345</td>\n",
       "      <td>DISPARADO!!! 90%... https://t.co/f5G9063duC</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>twe984494027956543488</td>\n",
       "      <td>O que acontece agora que o inqu√©rito de Alckmi...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twe981677295676084224</td>\n",
       "      <td>- \"a√©cio √© flagrado pedindo grana a empres√°rio...</td>\n",
       "      <td>temer</td>\n",
       "      <td>alysson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>twe978200570740822017</td>\n",
       "      <td>Se a bunda de algum ministro sentar sobre o pr...</td>\n",
       "      <td>lula</td>\n",
       "      <td>alysson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>twe982682347484180482</td>\n",
       "      <td>Hoje, n√£o h√° lado certo ou lado errado. Lula √©...</td>\n",
       "      <td>temer</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>twe984980191066849280</td>\n",
       "      <td>Decis√µes do STF e do STJ de encaminhar process...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>twe983555366133944320</td>\n",
       "      <td>PARA OS QUE AINDA N√ÉO SABEM! A pr√©-candidata √†...</td>\n",
       "      <td>marina</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                              tweet  \\\n",
       "2   twe984802485360582656  Ao inv√©s dos petistas estarem buscando livrar ...   \n",
       "3   twe977572021361168389  @CshmKnCaioHen @Peaotrabalhador @MiguelAMSA61 ...   \n",
       "4   twe977558211447443457  A pergunta √© s√©ria, @manudeputada: quer me pag...   \n",
       "5   twe977347407011897345        DISPARADO!!! 90%... https://t.co/f5G9063duC   \n",
       "6   twe984494027956543488  O que acontece agora que o inqu√©rito de Alckmi...   \n",
       "7   twe981677295676084224  - \"a√©cio √© flagrado pedindo grana a empres√°rio...   \n",
       "8   twe978200570740822017  Se a bunda de algum ministro sentar sobre o pr...   \n",
       "9   twe982682347484180482  Hoje, n√£o h√° lado certo ou lado errado. Lula √©...   \n",
       "10  twe984980191066849280  Decis√µes do STF e do STJ de encaminhar process...   \n",
       "11  twe983555366133944320  PARA OS QUE AINDA N√ÉO SABEM! A pr√©-candidata √†...   \n",
       "\n",
       "    candidato marcador classe  \n",
       "2     alckmin  alysson      2  \n",
       "3     manuela  alysson      1  \n",
       "4     manuela  alysson      2  \n",
       "5   bolsonaro  alysson      1  \n",
       "6     alckmin  alysson      1  \n",
       "7       temer  alysson      2  \n",
       "8        lula  alysson      2  \n",
       "9       temer  alysson      1  \n",
       "10    alckmin  alysson      1  \n",
       "11     marina  alysson      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(twitterText):\n",
    "    #Remover \\n\n",
    "    twitterText = re.sub(\"\\n+\",\" \",twitterText)\n",
    "\n",
    "    #Remover multiplos espa√ßos\n",
    "    twitterText = re.sub(\" +\",\" \",twitterText)\n",
    "    \n",
    "    #(@usu√°rio) pelo termo ‚ÄôAT_USER‚Äô tal como sugerido em [Almatrafi et al., 2015].\n",
    "    twitterText = re.sub(\"@\\w+\",\"atuser\",twitterText)\n",
    "\n",
    "    #Remove links\n",
    "    twitterText = re.sub(r\"http\\S+\", \"\",twitterText)\n",
    "\n",
    "    #Remover caracteres especiais\n",
    "    twitterText = re.sub(\"[@|#|‚Äú|‚Äù|‚Äô|‚Äò|¬Æ|,|!|?||\\[|\\]|\\.|\\\"|%|:|\\-|_|/|¬™|\\(|\\)|¬∞|\\*|üáß|üá∑|\\'|Ô∏è|=]\",'',twitterText)\n",
    "\n",
    "    #Remover n√∫meros\n",
    "    twitterText = re.sub(\"[0-9]+\",'',twitterText)\n",
    "\n",
    "    #Tokenize\n",
    "    twitterTokens = TweetTokenizer().tokenize(twitterText)\n",
    "\n",
    "    #transforme emojis em textcode\n",
    "    twitterTokensEmojisCode = []\n",
    "    for token in twitterTokens:\n",
    "        if(token in UNICODE_EMOJI):\n",
    "            twitterTokensEmojisCode.append(UNICODE_EMOJI[token])\n",
    "        else:\n",
    "            twitterTokensEmojisCode.append(token)\n",
    "    twitterTokens = twitterTokensEmojisCode\n",
    "\n",
    "    #remove stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    stopwords.remove(\"n√£o\")\n",
    "    stopwords.remove(\"num\")\n",
    "    twitterTokens = [token for token in twitterTokens if (token not in stopwords) ]\n",
    "    \n",
    "    #Lower case\n",
    "    twitterText = \"\".join(twitterText)\n",
    "    twitterText = twitterText.lower()\n",
    "\n",
    "    return twitterText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(lambda x : preProcessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>candidato</th>\n",
       "      <th>marcador</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twe984802485360582656</td>\n",
       "      <td>ao inv√©s dos petistas estarem buscando livrar ...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twe977572021361168389</td>\n",
       "      <td>atuser atuser atuser atuser o problema caio √© ...</td>\n",
       "      <td>manuela</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twe977558211447443457</td>\n",
       "      <td>a pergunta √© s√©ria atuser quer me pagar logo o...</td>\n",
       "      <td>manuela</td>\n",
       "      <td>alysson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>twe977347407011897345</td>\n",
       "      <td>disparado</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>twe984494027956543488</td>\n",
       "      <td>o que acontece agora que o inqu√©rito de alckmi...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                              tweet  \\\n",
       "2  twe984802485360582656  ao inv√©s dos petistas estarem buscando livrar ...   \n",
       "3  twe977572021361168389  atuser atuser atuser atuser o problema caio √© ...   \n",
       "4  twe977558211447443457  a pergunta √© s√©ria atuser quer me pagar logo o...   \n",
       "5  twe977347407011897345                                        disparado     \n",
       "6  twe984494027956543488  o que acontece agora que o inqu√©rito de alckmi...   \n",
       "\n",
       "   candidato marcador classe  \n",
       "2    alckmin  alysson      2  \n",
       "3    manuela  alysson      1  \n",
       "4    manuela  alysson      2  \n",
       "5  bolsonaro  alysson      1  \n",
       "6    alckmin  alysson      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['tweet']\n",
    "Y = data['classe'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply w2vec em X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGeneratorMedia:\n",
    "    def __init__(self, X, w2vmodel, num_features):\n",
    "        self.X = X\n",
    "        self.w2vmodel = w2vmodel\n",
    "        self.num_features = num_features\n",
    "        self.features_vec = None\n",
    "\n",
    "    def gen_features_dataset(self):\n",
    "        self.X = self.X.apply(lambda text: TweetTokenizer().tokenize(text) )\n",
    "        X_array = []\n",
    "        self.X.apply(lambda listText: X_array.append(self.make_features_vec(listText)) )\n",
    "        \n",
    "        return np.matrix(X_array)\n",
    "        \n",
    "    def make_features_vec(self, tweet):\n",
    "        featureVec = np.zeros(self.num_features)\n",
    "        nwords = 0.0\n",
    "        index2word_set = set(self.w2vmodel.wv.index2word)\n",
    "        for word in tweet:\n",
    "            if word in index2word_set:\n",
    "                featureVec = np.add(featureVec, self.w2vmodel[word])\n",
    "                nwords += 1\n",
    "        if nwords == 0.0:\n",
    "            nwords = 1.0\n",
    "        return np.divide(featureVec, nwords)\n",
    "\n",
    "def featureextractionWord2VecMean(X):\n",
    "    num_features=300\n",
    "    model = word2vec.Word2Vec.load(\"word2vec/tweets_presidential_elections_300_min1_cont2_cbow\")\n",
    "    featureGeneratorMedia = FeatureGeneratorMedia(X,model,num_features)\n",
    "    return featureGeneratorMedia.gen_features_dataset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romulo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "X = featureextractionWord2VecMean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the RNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load(\"word2vec/tweets_presidential_elections_300_min1_cont2_cbow\")\n",
    "vocab_size = len(model.wv.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec_dim=300\n",
    "output_dim=3\n",
    "lstm_dim=300\n",
    "dropout=0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,w2vec_dim,trainable=True))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(LSTM(lstm_dim))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "    \n",
    "model.compile('adam', 'categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         42329100  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 903       \n",
      "=================================================================\n",
      "Total params: 43,051,203\n",
      "Trainable params: 43,051,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (3,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-38b8b2435399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (3,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
